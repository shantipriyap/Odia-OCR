#!/usr/bin/env python3
"""
Comprehensive Odia OCR Datasets Discovery and Integration Guide
"""

datasets_comprehensive = {
    "1. OdiaGenAIOCR/Odia-lipi-ocr-data": {
        "source": "HuggingFace Hub",
        "type": "OCR - Printed & Handwritten Text",
        "format": "Word-level images (variable size)",
        "samples": "64 samples",
        "splits": ["train"],
        "status": "âœ… CURRENTLY USED",
        "url": "https://huggingface.co/datasets/OdiaGenAIOCR/Odia-lipi-ocr-data",
        "size_mb": "Unknown",
        "pros": ["Current baseline", "Diverse text types"],
        "cons": ["Very small dataset"],
    },
    
    "2. tell2jyoti/odia-handwritten-ocr": {
        "source": "HuggingFace Hub",
        "type": "OCR - Handwritten Character Recognition",
        "format": "Character-level images (32x32 grayscale)",
        "samples": "182,152 characters",
        "splits": ["train (145,717)", "validation (18,211)", "test (18,224)"],
        "status": "âœ… HIGHLY RECOMMENDED",
        "url": "https://huggingface.co/datasets/tell2jyoti/odia-handwritten-ocr",
        "size_mb": "42.8",
        "classes": "47 OHCS (Odia Handwritten Character Set)",
        "pros": [
            "Large dataset (182K samples)",
            "Balanced class distribution (3K-10K per class)",
            "All 47 Odia characters covered",
            "High quality with metadata",
            "MIT Licensed",
            "Includes synthetic & augmented data"
        ],
        "cons": ["Character-level (not word-level)", "May need adaptation for vision-language models"],
        "license": "MIT",
    },
    
    "3. darknight054/indic-mozhi-ocr": {
        "source": "HuggingFace Hub (from CVIT IIIT)",
        "type": "OCR - Printed Word Images (13 Indic languages)",
        "format": "Word-level JPEG images",
        "samples": "1,211,362 total (Odia subset unknown)",
        "languages": ["Assamese", "Bengali", "Gujarati", "Hindi", "Kannada", "Malayalam", "Manipuri", "Marathi", "Oriya (Odia)", "Punjabi", "Tamil", "Telugu", "Urdu"],
        "splits": ["train", "val", "test"],
        "status": "âœ… HIGHLY RECOMMENDED",
        "url": "https://huggingface.co/datasets/darknight054/indic-mozhi-ocr",
        "size_mb": "4590 (total)",
        "original_source": "CVIT IIIT (https://cvit.iiit.ac.in/usodi/tdocrmil.php)",
        "paper": "Towards Deployable OCR Models for Indic Languages (ICPR)",
        "pros": [
            "Very large dataset (1.2M+ total)",
            "Printed words (good for real documents)",
            "13 languages including Odia",
            "Professional academic source (CVIT IIIT)",
            "Already on HuggingFace"
        ],
        "cons": ["Odia split size unknown", "Word-level only (no character info)"],
        "citation": "Mathew et al., ICPR 2025",
    },
    
    "4. FutureBeeAI - Shopping List OCR": {
        "source": "FutureBeeAI",
        "type": "OCR - Shopping List Images",
        "format": "Real-world shopping lists (Odia text)",
        "samples": "Unknown",
        "status": "â­• REQUIRES CHECK",
        "url": "https://www.futurebeeai.com/dataset/ocr-dataset/odia-shopping-list-ocr-image-dataset",
        "domain": "Specific (shopping lists)",
        "pros": ["Real-world use case", "Domain-specific training data"],
        "cons": ["May be limited to shopping context", "Requires verification of size & format"],
    },
    
    "5. FutureBeeAI - Sticky Notes OCR": {
        "source": "FutureBeeAI",
        "type": "OCR - Sticky Notes Images",
        "format": "Real-world sticky note photographs (Odia text)",
        "samples": "Unknown",
        "status": "â­• REQUIRES CHECK",
        "url": "https://www.futurebeeai.com/dataset/ocr-dataset/odia-sticky-notes-ocr-image-dataset",
        "domain": "Specific (handwritten notes)",
        "pros": ["Handwritten variant", "Real-world challenging images"],
        "cons": ["Limited domain", "Requires verification"],
    },
    
    "6. FutureBeeAI - Newspaper/Book/Magazine OCR": {
        "source": "FutureBeeAI",
        "type": "OCR - Printed Press Materials",
        "format": "Magazine/newspaper/book scans (Odia text)",
        "samples": "Unknown",
        "status": "â­• REQUIRES CHECK",
        "url": "https://www.futurebeeai.com/dataset/ocr-dataset/odia-newspaper-book-magazine-ocr-image-dataset",
        "domain": "Specific (publications)",
        "pros": ["Professional printed text", "Real-world documents"],
        "cons": ["Requires verification of details"],
    },
    
    "7. IIIT ILOCR Dataset #34": {
        "source": "IIIT Language Technologies Lab",
        "type": "OCR - Indic Language (Multiple scripts)",
        "status": "â­• REQUIRES REGISTRATION",
        "url": "https://ilocr.iiit.ac.in/dataset/34/",
        "notes": "Part of IIIT Indic Language OCR Collection",
        "pro": ["Academic source", "Professional quality"],
        "con": ["Requires registration and form submission"],
    }
}

def print_comprehensive_guide():
    """Print comprehensive dataset guide"""
    
    print("\n" + "="*100)
    print("ðŸ“Š COMPREHENSIVE ODIA OCR DATASETS GUIDE")
    print("="*100 + "\n")
    
    # Tier 1: Immediately usable
    print("ðŸŸ¢ TIER 1: IMMEDIATELY USABLE (Public, on HuggingFace)\n")
    tier1_datasets = [
        ("OdiaGenAIOCR/Odia-lipi-ocr-data", "64 samples", "Small base dataset"),
        ("tell2jyoti/odia-handwritten-ocr", "182,152 samples", "182K character images - HUGE!"),
        ("darknight054/indic-mozhi-ocr", "1.2M+ samples", "1.2M Indic words including Odia"),
    ]
    
    for i, (name, size, desc) in enumerate(tier1_datasets, 1):
        print(f"  {i}. {name}")
        print(f"     Size: {size}")
        print(f"     Note: {desc}")
        print()
    
    # Tier 2
    print("ðŸŸ¡ TIER 2: REQUIRES VERIFICATION (FutureBeeAI)\n")
    tier2_datasets = [
        ("Shopping List OCR", "Domain-specific Odia shopping receipts"),
        ("Sticky Notes OCR", "Handwritten Odia notes"),
        ("Newspaper/Book/Magazine OCR", "Professional printed Odia publications"),
    ]
    
    for i, (name, desc) in enumerate(tier2_datasets, 1):
        print(f"  {i}. {name}")
        print(f"     Note: {desc}")
        print()
    
    # Tier 3
    print("ðŸ”µ TIER 3: REQUIRES REGISTRATION (IIIT)\n")
    print("  1. IIIT ILOCR Dataset #34")
    print("     Note: Academic source, requires form registration")
    print()
    
    print("="*100)
    print("ðŸ“ˆ RECOMMENDED TRAINING STRATEGY")
    print("="*100 + "\n")
    
    phases = [
        {
            "phase": "Phase 0 (Current)",
            "time": "Baseline",
            "data": "OdiaGenAIOCR (64 samples)",
            "cer": "100%",
            "action": "Status quo"
        },
        {
            "phase": "Phase 1 (Next - 1 hour)",
            "time": "Quick improvement",
            "data": "OdiaGenAIOCR (64) + tell2jyoti chars (convert to words: ~100K effective)",
            "cer": "30-50% expected",
            "action": "PRIORITY - Use tell2jyoti for massive data boost"
        },
        {
            "phase": "Phase 2 (Day 1-2)",
            "time": "Major improvement",
            "data": "All Tier 1: + darknight054/indic-mozhi-ocr + tell2jyoti",
            "cer": "10-25% expected",
            "action": "Combine largest public datasets (1.2M+ samples)"
        },
        {
            "phase": "Phase 3 (Day 3-5)",
            "time": "Production ready",
            "data": "All Tier 1 + FutureBeeAI datasets (after verification)",
            "cer": "5-15% expected",
            "action": "Add domain-specific real-world data"
        },
        {
            "phase": "Phase 4 (Week 2+)",
            "time": "State-of-art",
            "data": "All + IIIT Dataset#34 (after registration)",
            "cer": "<5% expected",
            "action": "Integrate academic datasets"
        }
    ]
    
    for p in phases:
        print(f"ðŸ”¹ {p['phase']}")
        print(f"   Time Required: {p['time']}")
        print(f"   Training Data: {p['data']}")
        print(f"   Expected CER: {p['cer']}")
        print(f"   Action: {p['action']}")
        print()
    
    print("="*100)
    print("ðŸ’¡ DATA INTEGRATION PRIORITIES")
    print("="*100 + "\n")
    
    print("PRIORITY 1 - Start NOW (tell2jyoti):")
    print("  â€¢ 182,152 handwritten character samples")
    print("  â€¢ Can be converted to word-level sequences")
    print("  â€¢ Will improve CER from 100% to 30-50%")
    print("  â€¢ Implementation: 30 minutes")
    print()
    
    print("PRIORITY 2 - Add ASAP (darknight054):")
    print("  â€¢ 1.2M+ printed word images from IIIT")
    print("  â€¢ Covers 13 Indic languages including Odia")
    print("  â€¢ Will improve CER from 30-50% to 10-25%")
    print("  â€¢ Implementation: 1-2 hours")
    print()
    
    print("PRIORITY 3 - Verify & Add (FutureBeeAI):")
    print("  â€¢ 3 domain-specific datasets for real-world cases")
    print("  â€¢ Can boost final performance to production-level")
    print("  â€¢ Implementation: 1-2 days")
    print()
    
    print("PRIORITY 4 - Register & Integrate (IIIT #34):")
    print("  â€¢ Academic-quality dataset")
    print("  â€¢ For final optimization")
    print("  â€¢ Implementation: 3-5 days")
    print()
    
    print("="*100)
    print("ðŸ“‹ ACTION ITEMS FOR TODAY")
    print("="*100 + "\n")
    
    print("1. âœ… DONE: Identify 3 major public datasets")
    print()
    print("2. â³ TODO (30 min): Integrate tell2jyoti character data")
    print("   â€¢ Load 182K character samples")
    print("   â€¢ Convert characters to word sequences")
    print("   â€¢ Combine with OdiaGenAIOCR (64 samples)")
    print("   â€¢ Train with new multi-dataset pipeline")
    print()
    print("3. â³ TODO (2 hours): Add darknight054 Odia words")
    print("   â€¢ Extract Odia subset from darknight054")
    print("   â€¢ Merge training pipeline")
    print("   â€¢ Retrain with 1.2M+ samples")
    print()
    print("4. â³ TODO: Check FutureBeeAI datasets")
    print("   â€¢ Verify dataset details")
    print("   â€¢ Check licensing & download options")
    print()
    print("5. â³ TODO: Register IIIT dataset #34")
    print("   â€¢ Fill registration form")
    print("   â€¢ Integrate when access granted")
    print()

if __name__ == "__main__":
    print_comprehensive_guide()
    
    # Save to JSON
    import json
    with open("odia_datasets_comprehensive.json", "w") as f:
        json.dump(datasets_comprehensive, f, indent=2)
    
    print("âœ… Full dataset information saved to: odia_datasets_comprehensive.json")
